{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'lr': 0.001,\n",
    "    'batch': 32,\n",
    "    'valid_size': 0.2,\n",
    "    'seed': 41,\n",
    "    'epoch':30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.MNIST(\n",
    "    root='./data/MNIST',\n",
    "    train=True,\n",
    "    download= True,\n",
    "    transform= transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/MNIST',\n",
    "    train=False,\n",
    "    download= True,\n",
    "    transform= transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 12000 10000\n"
     ]
    }
   ],
   "source": [
    "train_dataset,vali_dataset = train_test_split(train_set,test_size=params['valid_size'],random_state=params['seed'],shuffle=True )\n",
    "print(len(train_dataset), len(vali_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=params['batch'])\n",
    "valid_loader = torch.utils.data.DataLoader(vali_dataset,batch_size=params['batch'])\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=params['batch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class half_efficientNetb0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(half_efficientNetb0, self).__init__()\n",
    "        self.backbone = EfficientNet.from_pretrained('efficientnet-b0',in_channels=1,num_classes=10)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            self.backbone._conv_stem,\n",
    "            self.backbone._bn0\n",
    "        )\n",
    "        self.layer2 = self.backbone._blocks[0]\n",
    "        self.layer3 = nn.Sequential(\n",
    "            self.backbone._blocks[1],\n",
    "            self.backbone._blocks[2]\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            self.backbone._blocks[3],\n",
    "            self.backbone._blocks[4]\n",
    "        )\n",
    "        self.avg_pooling = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(in_features=40, out_features=10, bias=True)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avg_pooling(out)\n",
    "        out = out.flatten(start_dim=1)\n",
    "        out = self.fc(out)\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "model = half_efficientNetb0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         ZeroPad2d-1            [-1, 1, 29, 29]               0\n",
      "         ZeroPad2d-2            [-1, 1, 29, 29]               0\n",
      "Conv2dStaticSamePadding-3           [-1, 32, 14, 14]             288\n",
      "Conv2dStaticSamePadding-4           [-1, 32, 14, 14]             288\n",
      "       BatchNorm2d-5           [-1, 32, 14, 14]              64\n",
      "       BatchNorm2d-6           [-1, 32, 14, 14]              64\n",
      "         ZeroPad2d-7           [-1, 32, 16, 16]               0\n",
      "         ZeroPad2d-8           [-1, 32, 16, 16]               0\n",
      "Conv2dStaticSamePadding-9           [-1, 32, 14, 14]             288\n",
      "Conv2dStaticSamePadding-10           [-1, 32, 14, 14]             288\n",
      "      BatchNorm2d-11           [-1, 32, 14, 14]              64\n",
      "      BatchNorm2d-12           [-1, 32, 14, 14]              64\n",
      "MemoryEfficientSwish-13           [-1, 32, 14, 14]               0\n",
      "MemoryEfficientSwish-14           [-1, 32, 14, 14]               0\n",
      "         Identity-15             [-1, 32, 1, 1]               0\n",
      "         Identity-16             [-1, 32, 1, 1]               0\n",
      "Conv2dStaticSamePadding-17              [-1, 8, 1, 1]             264\n",
      "Conv2dStaticSamePadding-18              [-1, 8, 1, 1]             264\n",
      "MemoryEfficientSwish-19              [-1, 8, 1, 1]               0\n",
      "MemoryEfficientSwish-20              [-1, 8, 1, 1]               0\n",
      "         Identity-21              [-1, 8, 1, 1]               0\n",
      "         Identity-22              [-1, 8, 1, 1]               0\n",
      "Conv2dStaticSamePadding-23             [-1, 32, 1, 1]             288\n",
      "Conv2dStaticSamePadding-24             [-1, 32, 1, 1]             288\n",
      "         Identity-25           [-1, 32, 14, 14]               0\n",
      "         Identity-26           [-1, 32, 14, 14]               0\n",
      "Conv2dStaticSamePadding-27           [-1, 16, 14, 14]             512\n",
      "Conv2dStaticSamePadding-28           [-1, 16, 14, 14]             512\n",
      "      BatchNorm2d-29           [-1, 16, 14, 14]              32\n",
      "      BatchNorm2d-30           [-1, 16, 14, 14]              32\n",
      "      MBConvBlock-31           [-1, 16, 14, 14]               0\n",
      "      MBConvBlock-32           [-1, 16, 14, 14]               0\n",
      "         Identity-33           [-1, 16, 14, 14]               0\n",
      "         Identity-34           [-1, 16, 14, 14]               0\n",
      "Conv2dStaticSamePadding-35           [-1, 96, 14, 14]           1,536\n",
      "Conv2dStaticSamePadding-36           [-1, 96, 14, 14]           1,536\n",
      "      BatchNorm2d-37           [-1, 96, 14, 14]             192\n",
      "      BatchNorm2d-38           [-1, 96, 14, 14]             192\n",
      "MemoryEfficientSwish-39           [-1, 96, 14, 14]               0\n",
      "MemoryEfficientSwish-40           [-1, 96, 14, 14]               0\n",
      "        ZeroPad2d-41           [-1, 96, 15, 15]               0\n",
      "        ZeroPad2d-42           [-1, 96, 15, 15]               0\n",
      "Conv2dStaticSamePadding-43             [-1, 96, 7, 7]             864\n",
      "Conv2dStaticSamePadding-44             [-1, 96, 7, 7]             864\n",
      "      BatchNorm2d-45             [-1, 96, 7, 7]             192\n",
      "      BatchNorm2d-46             [-1, 96, 7, 7]             192\n",
      "MemoryEfficientSwish-47             [-1, 96, 7, 7]               0\n",
      "MemoryEfficientSwish-48             [-1, 96, 7, 7]               0\n",
      "         Identity-49             [-1, 96, 1, 1]               0\n",
      "         Identity-50             [-1, 96, 1, 1]               0\n",
      "Conv2dStaticSamePadding-51              [-1, 4, 1, 1]             388\n",
      "Conv2dStaticSamePadding-52              [-1, 4, 1, 1]             388\n",
      "MemoryEfficientSwish-53              [-1, 4, 1, 1]               0\n",
      "MemoryEfficientSwish-54              [-1, 4, 1, 1]               0\n",
      "         Identity-55              [-1, 4, 1, 1]               0\n",
      "         Identity-56              [-1, 4, 1, 1]               0\n",
      "Conv2dStaticSamePadding-57             [-1, 96, 1, 1]             480\n",
      "Conv2dStaticSamePadding-58             [-1, 96, 1, 1]             480\n",
      "         Identity-59             [-1, 96, 7, 7]               0\n",
      "         Identity-60             [-1, 96, 7, 7]               0\n",
      "Conv2dStaticSamePadding-61             [-1, 24, 7, 7]           2,304\n",
      "Conv2dStaticSamePadding-62             [-1, 24, 7, 7]           2,304\n",
      "      BatchNorm2d-63             [-1, 24, 7, 7]              48\n",
      "      BatchNorm2d-64             [-1, 24, 7, 7]              48\n",
      "      MBConvBlock-65             [-1, 24, 7, 7]               0\n",
      "      MBConvBlock-66             [-1, 24, 7, 7]               0\n",
      "         Identity-67             [-1, 24, 7, 7]               0\n",
      "         Identity-68             [-1, 24, 7, 7]               0\n",
      "Conv2dStaticSamePadding-69            [-1, 144, 7, 7]           3,456\n",
      "Conv2dStaticSamePadding-70            [-1, 144, 7, 7]           3,456\n",
      "      BatchNorm2d-71            [-1, 144, 7, 7]             288\n",
      "      BatchNorm2d-72            [-1, 144, 7, 7]             288\n",
      "MemoryEfficientSwish-73            [-1, 144, 7, 7]               0\n",
      "MemoryEfficientSwish-74            [-1, 144, 7, 7]               0\n",
      "        ZeroPad2d-75            [-1, 144, 9, 9]               0\n",
      "        ZeroPad2d-76            [-1, 144, 9, 9]               0\n",
      "Conv2dStaticSamePadding-77            [-1, 144, 7, 7]           1,296\n",
      "Conv2dStaticSamePadding-78            [-1, 144, 7, 7]           1,296\n",
      "      BatchNorm2d-79            [-1, 144, 7, 7]             288\n",
      "      BatchNorm2d-80            [-1, 144, 7, 7]             288\n",
      "MemoryEfficientSwish-81            [-1, 144, 7, 7]               0\n",
      "MemoryEfficientSwish-82            [-1, 144, 7, 7]               0\n",
      "         Identity-83            [-1, 144, 1, 1]               0\n",
      "         Identity-84            [-1, 144, 1, 1]               0\n",
      "Conv2dStaticSamePadding-85              [-1, 6, 1, 1]             870\n",
      "Conv2dStaticSamePadding-86              [-1, 6, 1, 1]             870\n",
      "MemoryEfficientSwish-87              [-1, 6, 1, 1]               0\n",
      "MemoryEfficientSwish-88              [-1, 6, 1, 1]               0\n",
      "         Identity-89              [-1, 6, 1, 1]               0\n",
      "         Identity-90              [-1, 6, 1, 1]               0\n",
      "Conv2dStaticSamePadding-91            [-1, 144, 1, 1]           1,008\n",
      "Conv2dStaticSamePadding-92            [-1, 144, 1, 1]           1,008\n",
      "         Identity-93            [-1, 144, 7, 7]               0\n",
      "         Identity-94            [-1, 144, 7, 7]               0\n",
      "Conv2dStaticSamePadding-95             [-1, 24, 7, 7]           3,456\n",
      "Conv2dStaticSamePadding-96             [-1, 24, 7, 7]           3,456\n",
      "      BatchNorm2d-97             [-1, 24, 7, 7]              48\n",
      "      BatchNorm2d-98             [-1, 24, 7, 7]              48\n",
      "      MBConvBlock-99             [-1, 24, 7, 7]               0\n",
      "     MBConvBlock-100             [-1, 24, 7, 7]               0\n",
      "        Identity-101             [-1, 24, 7, 7]               0\n",
      "        Identity-102             [-1, 24, 7, 7]               0\n",
      "Conv2dStaticSamePadding-103            [-1, 144, 7, 7]           3,456\n",
      "Conv2dStaticSamePadding-104            [-1, 144, 7, 7]           3,456\n",
      "     BatchNorm2d-105            [-1, 144, 7, 7]             288\n",
      "     BatchNorm2d-106            [-1, 144, 7, 7]             288\n",
      "MemoryEfficientSwish-107            [-1, 144, 7, 7]               0\n",
      "MemoryEfficientSwish-108            [-1, 144, 7, 7]               0\n",
      "       ZeroPad2d-109          [-1, 144, 10, 10]               0\n",
      "       ZeroPad2d-110          [-1, 144, 10, 10]               0\n",
      "Conv2dStaticSamePadding-111            [-1, 144, 3, 3]           3,600\n",
      "Conv2dStaticSamePadding-112            [-1, 144, 3, 3]           3,600\n",
      "     BatchNorm2d-113            [-1, 144, 3, 3]             288\n",
      "     BatchNorm2d-114            [-1, 144, 3, 3]             288\n",
      "MemoryEfficientSwish-115            [-1, 144, 3, 3]               0\n",
      "MemoryEfficientSwish-116            [-1, 144, 3, 3]               0\n",
      "        Identity-117            [-1, 144, 1, 1]               0\n",
      "        Identity-118            [-1, 144, 1, 1]               0\n",
      "Conv2dStaticSamePadding-119              [-1, 6, 1, 1]             870\n",
      "Conv2dStaticSamePadding-120              [-1, 6, 1, 1]             870\n",
      "MemoryEfficientSwish-121              [-1, 6, 1, 1]               0\n",
      "MemoryEfficientSwish-122              [-1, 6, 1, 1]               0\n",
      "        Identity-123              [-1, 6, 1, 1]               0\n",
      "        Identity-124              [-1, 6, 1, 1]               0\n",
      "Conv2dStaticSamePadding-125            [-1, 144, 1, 1]           1,008\n",
      "Conv2dStaticSamePadding-126            [-1, 144, 1, 1]           1,008\n",
      "        Identity-127            [-1, 144, 3, 3]               0\n",
      "        Identity-128            [-1, 144, 3, 3]               0\n",
      "Conv2dStaticSamePadding-129             [-1, 40, 3, 3]           5,760\n",
      "Conv2dStaticSamePadding-130             [-1, 40, 3, 3]           5,760\n",
      "     BatchNorm2d-131             [-1, 40, 3, 3]              80\n",
      "     BatchNorm2d-132             [-1, 40, 3, 3]              80\n",
      "     MBConvBlock-133             [-1, 40, 3, 3]               0\n",
      "     MBConvBlock-134             [-1, 40, 3, 3]               0\n",
      "        Identity-135             [-1, 40, 3, 3]               0\n",
      "        Identity-136             [-1, 40, 3, 3]               0\n",
      "Conv2dStaticSamePadding-137            [-1, 240, 3, 3]           9,600\n",
      "Conv2dStaticSamePadding-138            [-1, 240, 3, 3]           9,600\n",
      "     BatchNorm2d-139            [-1, 240, 3, 3]             480\n",
      "     BatchNorm2d-140            [-1, 240, 3, 3]             480\n",
      "MemoryEfficientSwish-141            [-1, 240, 3, 3]               0\n",
      "MemoryEfficientSwish-142            [-1, 240, 3, 3]               0\n",
      "       ZeroPad2d-143            [-1, 240, 7, 7]               0\n",
      "       ZeroPad2d-144            [-1, 240, 7, 7]               0\n",
      "Conv2dStaticSamePadding-145            [-1, 240, 3, 3]           6,000\n",
      "Conv2dStaticSamePadding-146            [-1, 240, 3, 3]           6,000\n",
      "     BatchNorm2d-147            [-1, 240, 3, 3]             480\n",
      "     BatchNorm2d-148            [-1, 240, 3, 3]             480\n",
      "MemoryEfficientSwish-149            [-1, 240, 3, 3]               0\n",
      "MemoryEfficientSwish-150            [-1, 240, 3, 3]               0\n",
      "        Identity-151            [-1, 240, 1, 1]               0\n",
      "        Identity-152            [-1, 240, 1, 1]               0\n",
      "Conv2dStaticSamePadding-153             [-1, 10, 1, 1]           2,410\n",
      "Conv2dStaticSamePadding-154             [-1, 10, 1, 1]           2,410\n",
      "MemoryEfficientSwish-155             [-1, 10, 1, 1]               0\n",
      "MemoryEfficientSwish-156             [-1, 10, 1, 1]               0\n",
      "        Identity-157             [-1, 10, 1, 1]               0\n",
      "        Identity-158             [-1, 10, 1, 1]               0\n",
      "Conv2dStaticSamePadding-159            [-1, 240, 1, 1]           2,640\n",
      "Conv2dStaticSamePadding-160            [-1, 240, 1, 1]           2,640\n",
      "        Identity-161            [-1, 240, 3, 3]               0\n",
      "        Identity-162            [-1, 240, 3, 3]               0\n",
      "Conv2dStaticSamePadding-163             [-1, 40, 3, 3]           9,600\n",
      "Conv2dStaticSamePadding-164             [-1, 40, 3, 3]           9,600\n",
      "     BatchNorm2d-165             [-1, 40, 3, 3]              80\n",
      "     BatchNorm2d-166             [-1, 40, 3, 3]              80\n",
      "     MBConvBlock-167             [-1, 40, 3, 3]               0\n",
      "     MBConvBlock-168             [-1, 40, 3, 3]               0\n",
      "AdaptiveAvgPool2d-169             [-1, 40, 1, 1]               0\n",
      "          Linear-170                   [-1, 10]             410\n",
      "         Softmax-171                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 130,718\n",
      "Trainable params: 130,718\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 4.55\n",
      "Params size (MB): 0.50\n",
      "Estimated Total Size (MB): 5.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model,(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model,criterion, validation_loader):\n",
    "    model.eval()\n",
    "    epoch_loss = 0 \n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(validation_loader):\n",
    "            data = data.float().to(params['device'])\n",
    "            target = target.to(params['device'])\n",
    "            target = F.one_hot(target, num_classes=10).float()\n",
    "            pred = model(data)\n",
    "            batch_loss = criterion(pred,target)\n",
    "            epoch_loss += batch_loss.item()\n",
    "        return epoch_loss/len(validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, valid_loader):\n",
    "    model = model.to(params['device'])\n",
    "    best_model = None\n",
    "    min_val_loss = float('inf')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = params['lr'])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-8, verbose=True)\n",
    "    for epoch in range(params['epoch']):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for data, target in tqdm(train_loader):\n",
    "            data = data.float().to(params['device'])\n",
    "            target = target.to(params['device'])\n",
    "            # target = F.one_hot(target, num_classes=10).float()\n",
    "            pred = model(data)\n",
    "            # print(pred[0],target[0])\n",
    "            batch_loss = criterion(pred,target)\n",
    "            \n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += batch_loss.item()\n",
    "        \n",
    "        valid_loss = validation(model, criterion, valid_loader)\n",
    "        scheduler.step(valid_loss)\n",
    "        \n",
    "        print(f'Epoch{epoch+1}, Train_loss: {epoch_loss/len(train_loader):6f}, Validation_loss: {valid_loss:6f}')\n",
    "        if min_val_loss>valid_loss:\n",
    "            min_val_loss = valid_loss\n",
    "            best_model = model\n",
    "            best_epoch = epoch+1\n",
    "            torch.save(best_model,'C:/cv_task/best_model.pt')\n",
    "            print('New best Model!')\n",
    "    print(f'TRAINING DONE\\nBest epoch: {best_epoch} at {min_val_loss:6f}')\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [01:58<00:00, 12.62it/s]\n",
      "100%|██████████| 375/375 [00:09<00:00, 41.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1, Train_loss: 1.565958, Validation_loss: 1.635330\n",
      "New best Model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 948/1500 [01:16<00:44, 12.38it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\cv_task\\model.ipynb 셀 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/cv_task/model.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m best_model \u001b[39m=\u001b[39m train(model,train_loader,valid_loader)\n",
      "\u001b[1;32mc:\\cv_task\\model.ipynb 셀 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/cv_task/model.ipynb#X22sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m target \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39mto(params[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/cv_task/model.ipynb#X22sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# target = F.one_hot(target, num_classes=10).float()\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/cv_task/model.ipynb#X22sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m pred \u001b[39m=\u001b[39m model(data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/cv_task/model.ipynb#X22sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# print(pred[0],target[0])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/cv_task/model.ipynb#X22sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m batch_loss \u001b[39m=\u001b[39m criterion(pred,target)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\cv_task\\model.ipynb 셀 14\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/cv_task/model.ipynb#X22sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(out)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/cv_task/model.ipynb#X22sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer3(out)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/cv_task/model.ipynb#X22sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer4(out)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/cv_task/model.ipynb#X22sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavg_pooling(out)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/cv_task/model.ipynb#X22sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mflatten(start_dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\efficientnet_pytorch\\model.py:119\u001b[0m, in \u001b[0;36mMBConvBlock.forward\u001b[1;34m(self, inputs, drop_connect_rate)\u001b[0m\n\u001b[0;32m    117\u001b[0m     x_squeezed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_swish(x_squeezed)\n\u001b[0;32m    118\u001b[0m     x_squeezed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_se_expand(x_squeezed)\n\u001b[1;32m--> 119\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49msigmoid(x_squeezed) \u001b[39m*\u001b[39m x\n\u001b[0;32m    121\u001b[0m \u001b[39m# Pointwise Convolution\u001b[39;00m\n\u001b[0;32m    122\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_project_conv(x)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model = train(model,train_loader,valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        model.eval()\n",
    "        for data, target in tqdm(test_loader):\n",
    "            data = data.float().to(params['device'])\n",
    "            target = target.to(params['device'])\n",
    "            pred = model(data)\n",
    "            pred = torch.max(pred,1)[1]\n",
    "            print(pred.shape)\n",
    "            total+=len(target)\n",
    "            correct+=(pred==target).sum().item()\n",
    "        print(f'Test accuracy: {correct/total*100:3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(best_model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
